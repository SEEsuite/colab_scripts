{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfQqyTJE6oCiozgIeeOfpP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEEsuite/colab_scripts/blob/main/get_twitter_edge_list.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Edge List from set of Tweets\n",
        "\n",
        "Nodes: users, labeled by username\n",
        "\n",
        "All edges will composed of mentions, a directed edge from the author to the mentioned user\n",
        "\n",
        "Edge Labels  = ['Direct', 'Retweet', 'Reply', 'Self']\n",
        "\n",
        "Note - Significantly, we cannot determine a Quote tweet edge from text.\n",
        "\n",
        "The script finds edges based on brandwatch \"Full Text\" Column. At the end, appends some extra columns to the edge list, so if you do not have the standard brandwatch dataset, this script might fail. Change column names as needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "JFghtF2odUZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "iUgHFJHdi7F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of tweets\n",
        "\n",
        "\n",
        "import urllib.request\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def import_data_from_drive(share_link, your_name_for_file=\"my_data\"):\n",
        "  \"\"\"Brings data file from a google drive sharepoint to your colab workspace.\n",
        "     It does not require you to host the dataset on your own account.\n",
        "\n",
        "     Parameters:\n",
        "     share_link: the link to view a file in google drive\n",
        "     our_name_for_file: a string describing the file, preferable endling in a file type, ex. 'data.csv'\n",
        "     \"\"\"\n",
        "  id = share_link.split(\"/\")[5] # separate the id from the link\n",
        "  print(\"Using id\", id, \"to find file on drive\")\n",
        "\n",
        "  # use pydrive and colab modules to authenticate you\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"Authenticated colab user\")\n",
        "\n",
        "  # This step will move the file from Drive to the workspace\n",
        "  download_object = drive.CreateFile({'id':id}) \n",
        "  download_object.GetContentFile(your_name_for_file)\n",
        "  print(\"Added file to workspace with name\", your_name_for_file)\n",
        "\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "id": "smBdHaMnkPbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### HERE IS THE CELL YOU NEED TO CHANGE\n",
        "link = \"https://docs.google.com/spreadsheets/d/15Coav23He83KEwkr7w4b1-Z4cF9BAf8p/edit?usp=sharing&ouid=101042095541764641159&rtpof=true&sd=true\"\n",
        "### IF YOUR DATASET DOES NOT USE STANDARD BRANDWATCH COLUMN NAMES YOU WILL NEED TO CHANGE THE EXCEL NAMES OR THE DF NAMES BELOW\n",
        "\n",
        "import_data_from_drive(link, your_name_for_file=\"tweets.xlsx\")\n",
        "df = pd.read_excel('tweets.xlsx')\n",
        "# df = pd.read_excel('tweets.xlsx', header=8)\n"
      ],
      "metadata": {
        "id": "KugtOm5ykMs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ps3BYJyokaWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "caqwtwbKUzAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imma do the best I can with raw text\n",
        "\n",
        "def get_edges(row):\n",
        "  tweet = row.text\n",
        "  author = row.Author\n",
        "  handles = []\n",
        "  edge_list = []\n",
        "  temp = tweet.split()\n",
        "\n",
        "  mentions = re.findall(\"@[A-Za-z0-9_]+\", tweet)\n",
        "  num_mentions = len(mentions)\n",
        "\n",
        "\n",
        "  if num_mentions < 1: #if we've found no mentions \n",
        "     edge = (author, 'self')# sometimes there will be (author, 'reply') when they start a thread.\n",
        "     edge_list.append(edge)\n",
        "     return edge_list\n",
        "\n",
        "  # if there are mentions leading the tweet\n",
        "  if tweet[0] == '@':   \n",
        "    for i, word in enumerate(temp):\n",
        "      if word[0] != '@':\n",
        "        break\n",
        "      edge = (word[1:], 'reply')\n",
        "      edge_list.append(edge)\n",
        "  elif temp[0] == 'RT':\n",
        "    first_mention = re.search(\"@[A-Za-z0-9_]+\",\" \".join(temp)).group(0)\n",
        "    edge_list.append((first_mention, 'Retweet'))\n",
        "    temp = temp[2:]\n",
        "\n",
        "\n",
        "  print(\" \".join(temp))\n",
        "\n",
        "  #TODO - check for quote connection\n",
        "\n",
        "  num_mentions_remaining = len(re.findall(\"@[A-Za-z0-9_]+\", \" \".join(temp)))\n",
        "  if  num_mentions_remaining > 0:\n",
        "    for i, word in enumerate(temp):\n",
        "      if word[0] != '@':\n",
        "        continue\n",
        "      edge = (word[1:-1], 'direct')\n",
        "      edge_list.append(edge)\n",
        "      temp.pop(i)\n",
        " \n",
        "  if len(edge_list) < 1: #if we've found no mentions \n",
        "     edge = (author, 'self')# sometimes there will be (author, 'reply') when they start a thread.\n",
        "\n",
        "  return edge_list\n",
        "\n"
      ],
      "metadata": {
        "id": "odBpayqriomK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['Full Text']"
      ],
      "metadata": {
        "id": "Jtxbn54AxvQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['edge_list'] = df.apply(get_edges, axis=1)"
      ],
      "metadata": {
        "id": "Sx02_cagiot1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['edge_list'][9])\n",
        "df.iloc[9:10]"
      ],
      "metadata": {
        "id": "sx456vVFio0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enlarged_df = df.explode(column='edge_list', ignore_index=True)"
      ],
      "metadata": {
        "id": "__NyfsjYio9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enlarged_df.columns"
      ],
      "metadata": {
        "id": "GcQbtpbnSkgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "final_df = pd.DataFrame(enlarged_df['edge_list'].tolist(), columns=['Vertex B', 'Edge Label'])\n",
        "\n",
        "final_df.insert(0, \"Vertex A\",  enlarged_df['Author'])\n",
        "\n",
        "carry_over = enlarged_df[['Date','Full Text', 'Url', 'Sentiment', \"Emotion\", \"Language\", \"Country Code\", \"Author\", \"Interest\", \"Location Name\", \"Expanded URLs\", \"Twitter Followers\", \"Twitter Following\" , \"Twitter Likes\", \"Twitter Retweets\", \"Twitter Tweets\" , \"Reach (new)\"]]\n",
        "\n",
        "\n",
        "print(len(final_df))\n",
        "print(len(carry_over))\n",
        "\n",
        "final_df = pd.concat([final_df, carry_over], axis=1)\n",
        "print(len(final_df))\n",
        "\n"
      ],
      "metadata": {
        "id": "DKl6IbKbzrwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "id": "RIP0JoEt1zDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_excel(\"edge_list_and_twitter_attributes.xlsx\")"
      ],
      "metadata": {
        "id": "s0dB6ari10k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKWfzmvMVs70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
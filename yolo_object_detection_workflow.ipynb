{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEEsuite/colab_scripts/blob/main/yolo_object_detection_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOD0N9B7wcD8"
      },
      "source": [
        "### Workshop - Writing queries for joint models. \n",
        "[model](https://huggingface.co/valentinafeve/yolos-fashionpedia) \n",
        "\n",
        "This mdel has been specifically trained on a small cluster of objects. There are a lot of yolo models on hugginface trained on different things. This one is trained on fashion articles. and colab may give you some pushback. When in doubt, restart the session.\n",
        "\n",
        "We pull images from instagram using a temporary url. this url has to be regenerated every week, unfortunately. I'll provide you with a separate script to do that.\n",
        "\n",
        "This program will return labels, bounding boxes, and scores for each image post . I still don't think this format is going to be incredibly helpful - I'll look a better way to save the images so that you can instantly click on the image in concern.\n",
        "\n",
        "Please enter labels into the text variable, formatting them in natural language.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CHANGE THIS\n",
        "link = \"https://docs.google.com/spreadsheets/d/1UZkl8R0963yWcGxno0RZ0DBW0sEx_zZD/edit?usp=sharing&ouid=101042095541764641159&rtpof=true&sd=true\"\n",
        "#THE SCRIPT EXPECTS A COLUMN CALLED 'temporary_urls' CONTAINING URL TO IMAGE"
      ],
      "metadata": {
        "id": "pHVh3AxbpLAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Images.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pC5C6padn87B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xst_gzdREDTm"
      },
      "source": [
        "# Use on Your Own Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "clGgVwAfaQzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30455a6-e589-41cd-d8b3-f4ec8c55baff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri6t3CnHCvpc"
      },
      "outputs": [],
      "source": [
        "# importing miscelaneaous packages \n",
        "import numpy as np # fast manipulation of multidimensional arrays\n",
        "from numpy import mean\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from tqdm.notebook import tqdm as progress_bar # a little vizualization of how fast a loop is running\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "\n",
        "#dealing with images\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# helps with API request\n",
        "import requests\n",
        "\n",
        "# help with deep learning\n",
        "from datasets import Dataset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3qtvfZBCf88"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def import_data_from_drive(share_link, your_name_for_file=\"my_data\"):\n",
        "  \"\"\"Brings data file from a google drive sharepoint to your colab workspace.\n",
        "     It does not require you to host the dataset on your own account.\n",
        "\n",
        "     Parameters:\n",
        "     share_link: the link to view a file in google drive\n",
        "     our_name_for_file: a string describing the file, preferable endling in a file type, ex. 'data.csv'\n",
        "     \"\"\"\n",
        "  id = share_link.split(\"/\")[5] # separate the id from the link\n",
        "  print(\"Using id\", id, \"to find file on drive\")\n",
        "\n",
        "  # use pydrive and colab modules to authenticate you\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"Authenticated colab user\")\n",
        "\n",
        "  # This step will move the file from Drive to the workspace\n",
        "  download_object = drive.CreateFile({'id':id}) \n",
        "  download_object.GetContentFile(your_name_for_file)\n",
        "  print(\"Added file to workspace with name\", your_name_for_file)\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra4MMQ18Cgcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f30eb8b-b44d-42a2-aba5-162a85c864dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using id 1UZkl8R0963yWcGxno0RZ0DBW0sEx_zZD to find file on drive\n",
            "Authenticated colab user\n",
            "Added file to workspace with name insta.xlsx\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import_data_from_drive(link, your_name_for_file=\"insta.xlsx\")\n",
        "df = pd.read_excel('insta.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_Dg_lPsphOKG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "e5925028-7a06-4260-ab22-e5a3488d95de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Query Id         Query Name                     Date  \\\n",
              "0     2001569258  Sponsored IG test  2023-01-01 00:50:40.000   \n",
              "1     2001569258  Sponsored IG test  2022-12-31 20:37:05.000   \n",
              "2     2001569258  Sponsored IG test  2022-12-31 20:37:05.000   \n",
              "3     2001569258  Sponsored IG test  2022-12-31 20:37:05.000   \n",
              "4     2001569258  Sponsored IG test  2022-12-31 20:37:05.000   \n",
              "...          ...                ...                      ...   \n",
              "1547  2001569258  Sponsored IG test  2022-01-02 19:47:14.000   \n",
              "1548  2001569258  Sponsored IG test  2022-01-02 11:43:01.000   \n",
              "1549  2001569258  Sponsored IG test  2022-01-02 04:57:29.000   \n",
              "1550  2001569258  Sponsored IG test  2022-01-02 03:51:47.000   \n",
              "1551  2001569258  Sponsored IG test  2022-01-02 02:07:29.000   \n",
              "\n",
              "                                                  Title  \\\n",
              "0     üíôüñ§ #explorepage #blackgaymen #face #lgbt #mode...   \n",
              "1     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "2     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "3     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "4     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "...                                                 ...   \n",
              "1547  have the holidays stressed you out? are you si...   \n",
              "1548  A volte sono anche vestito üòåü§úüèª - - - - - - - -...   \n",
              "1549  Come to my aid babies! üò¢ I'm waiting for you i...   \n",
              "1550  This New Years hangover is #sponsored by heyya...   \n",
              "1551  Feliz 2022! ‚ù§Ô∏èü•≥ . . . . . hashtagsemportugues ...   \n",
              "\n",
              "                                                Snippet  \\\n",
              "0     üíôüñ§ #explorepage #blackgaymen #face #lgbt #mode...   \n",
              "1     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "2     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "3     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "4     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "...                                                 ...   \n",
              "1547  ...#sundayscaries #goth #gothgoth #sponsored #...   \n",
              "1548  A volte sono anche vestito üòåü§úüèª - - - - - - - -...   \n",
              "1549  ...#lgbt #following #toesucking #americanguys ...   \n",
              "1550  This New Years hangover is #sponsored by heyya...   \n",
              "1551  Feliz 2022! ‚ù§Ô∏èü•≥ . . . . . hashtagsemportugues ...   \n",
              "\n",
              "                                              Full Text  \\\n",
              "0     üíôüñ§ #explorepage #blackgaymen #face #lgbt #mode...   \n",
              "1     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "2     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "3     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "4     Stay tuned for our future episodes!! Here‚Äôs ou...   \n",
              "...                                                 ...   \n",
              "1547  have the holidays stressed you out? are you si...   \n",
              "1548  A volte sono anche vestito üòåü§úüèª - - - - - - - -...   \n",
              "1549  Come to my aid babies! üò¢ I'm waiting for you i...   \n",
              "1550  This New Years hangover is #sponsored by heyya...   \n",
              "1551  Feliz 2022! ‚ù§Ô∏èü•≥ . . . . . hashtagsemportugues ...   \n",
              "\n",
              "                                           Url         Domain Sentiment  \\\n",
              "0     https://www.instagram.com/p/Cm2mIrYrUJb/  instagram.com   neutral   \n",
              "1     https://www.instagram.com/p/Cm2JHTGPSKT/  instagram.com   neutral   \n",
              "2     https://www.instagram.com/p/Cm2JHTGPSKT/  instagram.com   neutral   \n",
              "3     https://www.instagram.com/p/Cm2JHTGPSKT/  instagram.com   neutral   \n",
              "4     https://www.instagram.com/p/Cm2JHTGPSKT/  instagram.com   neutral   \n",
              "...                                        ...            ...       ...   \n",
              "1547  https://www.instagram.com/p/CYPW2pDvrOe/  instagram.com  negative   \n",
              "1548  https://www.instagram.com/p/CYOfcGLs8__/  instagram.com   neutral   \n",
              "1549  https://www.instagram.com/p/CYNxB2XKj7-/  instagram.com  positive   \n",
              "1550  https://www.instagram.com/p/CYNpgrzLiSN/  instagram.com   neutral   \n",
              "1551  https://www.instagram.com/p/CYNdkzFr5OM/  instagram.com  negative   \n",
              "\n",
              "      Emotion  ... Reach (new) Reddit Score  Reddit Score Upvote Ratio  \\\n",
              "0         Joy  ...         380          NaN                        NaN   \n",
              "1         Joy  ...         949          NaN                        NaN   \n",
              "2         Joy  ...         949          NaN                        NaN   \n",
              "3         Joy  ...         949          NaN                        NaN   \n",
              "4         Joy  ...         949          NaN                        NaN   \n",
              "...       ...  ...         ...          ...                        ...   \n",
              "1547      NaN  ...        4081          NaN                        NaN   \n",
              "1548      NaN  ...        4304          NaN                        NaN   \n",
              "1549  Sadness  ...         574          NaN                        NaN   \n",
              "1550      NaN  ...        2399          NaN                        NaN   \n",
              "1551      NaN  ...         580          NaN                        NaN   \n",
              "\n",
              "      Reddit Author Karma  Reddit Author Awardee Karma  \\\n",
              "0                     NaN                          NaN   \n",
              "1                     NaN                          NaN   \n",
              "2                     NaN                          NaN   \n",
              "3                     NaN                          NaN   \n",
              "4                     NaN                          NaN   \n",
              "...                   ...                          ...   \n",
              "1547                  NaN                          NaN   \n",
              "1548                  NaN                          NaN   \n",
              "1549                  NaN                          NaN   \n",
              "1550                  NaN                          NaN   \n",
              "1551                  NaN                          NaN   \n",
              "\n",
              "      Reddit Author Awarder Karma  Reddit Comments  Subreddit  \\\n",
              "0                             NaN              NaN        NaN   \n",
              "1                             NaN              NaN        NaN   \n",
              "2                             NaN              NaN        NaN   \n",
              "3                             NaN              NaN        NaN   \n",
              "4                             NaN              NaN        NaN   \n",
              "...                           ...              ...        ...   \n",
              "1547                          NaN              NaN        NaN   \n",
              "1548                          NaN              NaN        NaN   \n",
              "1549                          NaN              NaN        NaN   \n",
              "1550                          NaN              NaN        NaN   \n",
              "1551                          NaN              NaN        NaN   \n",
              "\n",
              "      Subreddit Subscribers                                     temporary_urls  \n",
              "0                       NaN  ['https://scontent-dfw5-1.cdninstagram.com/v/t...  \n",
              "1                       NaN  ['https://scontent-dfw5-2.cdninstagram.com/v/t...  \n",
              "2                       NaN  ['https://scontent-dfw5-2.cdninstagram.com/v/t...  \n",
              "3                       NaN  ['https://scontent-dfw5-2.cdninstagram.com/v/t...  \n",
              "4                       NaN  ['https://scontent-dfw5-1.cdninstagram.com/v/t...  \n",
              "...                     ...                                                ...  \n",
              "1547                    NaN  ['https://scontent-dfw5-2.cdninstagram.com/v/t...  \n",
              "1548                    NaN  ['https://scontent-dfw5-2.cdninstagram.com/v/t...  \n",
              "1549                    NaN  ['https://scontent-dfw5-1.cdninstagram.com/v/t...  \n",
              "1550                    NaN  ['https://scontent-dfw5-2.cdninstagram.com/v/t...  \n",
              "1551                    NaN  ['https://scontent-dfw5-1.cdninstagram.com/v/t...  \n",
              "\n",
              "[1552 rows x 87 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50cb8af8-401d-4a9f-be3d-f59f9466a040\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query Id</th>\n",
              "      <th>Query Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>Title</th>\n",
              "      <th>Snippet</th>\n",
              "      <th>Full Text</th>\n",
              "      <th>Url</th>\n",
              "      <th>Domain</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>...</th>\n",
              "      <th>Reach (new)</th>\n",
              "      <th>Reddit Score</th>\n",
              "      <th>Reddit Score Upvote Ratio</th>\n",
              "      <th>Reddit Author Karma</th>\n",
              "      <th>Reddit Author Awardee Karma</th>\n",
              "      <th>Reddit Author Awarder Karma</th>\n",
              "      <th>Reddit Comments</th>\n",
              "      <th>Subreddit</th>\n",
              "      <th>Subreddit Subscribers</th>\n",
              "      <th>temporary_urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2023-01-01 00:50:40.000</td>\n",
              "      <td>üíôüñ§ #explorepage #blackgaymen #face #lgbt #mode...</td>\n",
              "      <td>üíôüñ§ #explorepage #blackgaymen #face #lgbt #mode...</td>\n",
              "      <td>üíôüñ§ #explorepage #blackgaymen #face #lgbt #mode...</td>\n",
              "      <td>https://www.instagram.com/p/Cm2mIrYrUJb/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Joy</td>\n",
              "      <td>...</td>\n",
              "      <td>380</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-1.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-12-31 20:37:05.000</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>https://www.instagram.com/p/Cm2JHTGPSKT/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Joy</td>\n",
              "      <td>...</td>\n",
              "      <td>949</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-2.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-12-31 20:37:05.000</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>https://www.instagram.com/p/Cm2JHTGPSKT/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Joy</td>\n",
              "      <td>...</td>\n",
              "      <td>949</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-2.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-12-31 20:37:05.000</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>https://www.instagram.com/p/Cm2JHTGPSKT/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Joy</td>\n",
              "      <td>...</td>\n",
              "      <td>949</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-2.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-12-31 20:37:05.000</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>Stay tuned for our future episodes!! Here‚Äôs ou...</td>\n",
              "      <td>https://www.instagram.com/p/Cm2JHTGPSKT/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Joy</td>\n",
              "      <td>...</td>\n",
              "      <td>949</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-1.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1547</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-01-02 19:47:14.000</td>\n",
              "      <td>have the holidays stressed you out? are you si...</td>\n",
              "      <td>...#sundayscaries #goth #gothgoth #sponsored #...</td>\n",
              "      <td>have the holidays stressed you out? are you si...</td>\n",
              "      <td>https://www.instagram.com/p/CYPW2pDvrOe/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>negative</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>4081</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-2.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1548</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-01-02 11:43:01.000</td>\n",
              "      <td>A volte sono anche vestito üòåü§úüèª - - - - - - - -...</td>\n",
              "      <td>A volte sono anche vestito üòåü§úüèª - - - - - - - -...</td>\n",
              "      <td>A volte sono anche vestito üòåü§úüèª - - - - - - - -...</td>\n",
              "      <td>https://www.instagram.com/p/CYOfcGLs8__/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>4304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-2.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-01-02 04:57:29.000</td>\n",
              "      <td>Come to my aid babies! üò¢ I'm waiting for you i...</td>\n",
              "      <td>...#lgbt #following #toesucking #americanguys ...</td>\n",
              "      <td>Come to my aid babies! üò¢ I'm waiting for you i...</td>\n",
              "      <td>https://www.instagram.com/p/CYNxB2XKj7-/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>positive</td>\n",
              "      <td>Sadness</td>\n",
              "      <td>...</td>\n",
              "      <td>574</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-1.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1550</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-01-02 03:51:47.000</td>\n",
              "      <td>This New Years hangover is #sponsored by heyya...</td>\n",
              "      <td>This New Years hangover is #sponsored by heyya...</td>\n",
              "      <td>This New Years hangover is #sponsored by heyya...</td>\n",
              "      <td>https://www.instagram.com/p/CYNpgrzLiSN/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2399</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-2.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1551</th>\n",
              "      <td>2001569258</td>\n",
              "      <td>Sponsored IG test</td>\n",
              "      <td>2022-01-02 02:07:29.000</td>\n",
              "      <td>Feliz 2022! ‚ù§Ô∏èü•≥ . . . . . hashtagsemportugues ...</td>\n",
              "      <td>Feliz 2022! ‚ù§Ô∏èü•≥ . . . . . hashtagsemportugues ...</td>\n",
              "      <td>Feliz 2022! ‚ù§Ô∏èü•≥ . . . . . hashtagsemportugues ...</td>\n",
              "      <td>https://www.instagram.com/p/CYNdkzFr5OM/</td>\n",
              "      <td>instagram.com</td>\n",
              "      <td>negative</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>580</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://scontent-dfw5-1.cdninstagram.com/v/t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1552 rows √ó 87 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50cb8af8-401d-4a9f-be3d-f59f9466a040')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50cb8af8-401d-4a9f-be3d-f59f9466a040 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50cb8af8-401d-4a9f-be3d-f59f9466a040');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### This will reformat the urls if they are getting stored funny. (I think saving the df is messing with them sometimes)\n",
        "def app(url):\n",
        "  return url.strip(']\\'[').split(', ')\n",
        "\n",
        "df[\"temporary_urls\"] = df[\"temporary_urls\"].apply(app)"
      ],
      "metadata": {
        "id": "EP5vT2kjiOjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjsYo8zkCgkP"
      },
      "outputs": [],
      "source": [
        "def to_pillow(batch):\n",
        "    \"\"\" a transformation to be applyed to a dataset. takes in a url string and returns data with a new column\"\"\"\n",
        "    images = []\n",
        "    for url_list in batch['temporary_urls']:\n",
        "      # print(url_list)\n",
        "      for url in url_list: # I need to get this running for multiple images per post\n",
        "        # print(url)\n",
        "        try:\n",
        "          http_image = requests.get(url, stream=True).raw #1\n",
        "          image = Image.open(http_image) # step 2\n",
        "          # print(type(http_image))\n",
        "          # image.show()\n",
        "          # print(type(image))\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          image = None\n",
        "        images.append(image)\n",
        "    batch['images'] = images # will probably need to expand this out in practice\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juP4iMrrDQpX"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset.from_pandas(df)\n",
        "dataset.set_transform(to_pillow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMRmi3-9aFDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "96abde96-5ecc-4430-91da-47d7cc09cee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://scontent-dfw5-1.cdninstagram.com/v/t51.29350-15/323568938_211520117902124_3209011309299629821_n.jpg?stp=dst-jpg_s640x640&_nc_cat=105&ccb=1-7&_nc_sid=8ae9d6&_nc_ohc=kvYJ3F0tLO8AX8nS0q3&_nc_ht=scontent-dfw5-1.cdninstagram.com&oh=00_AfDkHP_v8_wcgreqFNABAiW4bq-YmEavp6iZCpxu-0KMtA&oe=643A5968'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df['temporary_urls'][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDEfJBEVhSDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1cf3cb-e996-4abd-ac63-c3d6ad83704a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/yolos/feature_extraction_yolos.py:28: FutureWarning: The class YolosFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use YolosImageProcessor instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/yolos/image_processing_yolos.py:710: FutureWarning: The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import YolosFeatureExtractor, YolosForObjectDetection\n",
        "from transformers import AutoFeatureExtractor, AutoModelForObjectDetection\n",
        "\n",
        "processor = AutoFeatureExtractor.from_pretrained(\"valentinafeve/yolos-fashionpedia\")\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"valentinafeve/yolos-fashionpedia\")\n",
        "label_names = ['shirt, blouse', 'top, t-shirt, sweatshirt', 'sweater', 'cardigan', 'jacket', 'vest', 'pants', 'shorts', 'skirt', 'coat', 'dress', 'jumpsuit', 'cape', 'glasses', 'hat', 'headband, head covering, hair accessory', 'tie', 'glove', 'watch', 'belt', 'leg warmer', 'tights, stockings', 'sock', 'shoe', 'bag, wallet', 'scarf', 'umbrella', 'hood', 'collar', 'lapel', 'epaulette', 'sleeve', 'pocket', 'neckline', 'buckle', 'zipper', 'applique', 'bead', 'bow', 'flower', 'fringe', 'ribbon', 'rivet', 'ruffle', 'sequin', 'tassel']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qfkjAND_zSes",
        "outputId": "96011757-d972-4432-9fc6-6c6c180accb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'top, t-shirt, sweatshirt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjYh1zMFD4O7"
      },
      "outputs": [],
      "source": [
        "#Just copy and pasted from image_analysis_1!\n",
        "predictions = pd.DataFrame(columns=[\"post_url\", 'query_match', 'score', 'bounding_box','total_size'])\n",
        "model.to('cuda')\n",
        "\n",
        "# veiw the image live. Will weigh colab down - I need to look into this. \n",
        "print_image = False\n",
        "\n",
        "for data in progress_bar(dataset): # change 1\n",
        "\n",
        "  #pass images through the preprocessor\n",
        "  # texts = [[ \"a cat\", \"a dog\", \"a closeup photo of a persons face\", \"a book\", \"a poster\", \"a group of people laughing together\", \"a bench\", \"a cup\", \"a cup held in someone's hand\",  \"a hand with manicured nails\"]]\n",
        "  images = data['images']\n",
        "\n",
        "  # print(len(image))\n",
        "\n",
        "  if images:\n",
        "    inputs = processor(images=images, return_tensors=\"pt\").to('cuda')# change 2\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "  with torch.no_grad():\n",
        "    #TODO is resize neccesary?\n",
        "    if print_image:\n",
        "      images.show()\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Target image sizes (height, width) to rescale box predictions [batch_size, 2]\n",
        "    target_sizes = torch.Tensor([images.size[::-1]]).to('cuda')\n",
        "    # Convert outputs (bounding boxes and class logits) to COCO API\n",
        "    results = processor.post_process(outputs=outputs, target_sizes=target_sizes)\n",
        "\n",
        "    i = 0  # Retrieve predictions for the first image for the corresponding text queries\n",
        "    boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
        "\n",
        "    if len(labels) == 0:\n",
        "      continue\n",
        "     # Print detected objects and rescaled box coordinates\n",
        "    score_threshold = 0.15\n",
        "    for box, score, label in zip(boxes, scores, label):\n",
        "      box = [round(i, 2) for i in box.tolist()]\n",
        "      if score >= score_threshold:\n",
        "        try:\n",
        "          print(f\"Detected {label_names[label]} \")\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          print(label)\n",
        "          continue\n",
        "\n",
        "\n",
        "        if print_image:\n",
        "          img1 = ImageDraw.Draw(images)  \n",
        "          img1.rectangle(box, outline =\"green\")\n",
        "          images.show()\n",
        "\n",
        "        # save these\n",
        "        pred_row = pd.DataFrame(columns=[\"post_url\", 'query_match', 'score', 'bounding_box', 'total_size'])\n",
        "        pred_row[\"post_url\"] = [data['Url']]\n",
        "        pred_row[\"query_match\"] = [label_names[label].item()]\n",
        "        pred_row[\"score\"] = [score.item()]\n",
        "        pred_row.at[0, \"bounding_box\"] = box\n",
        "        pred_row.at[0, \"total_size\"] = images.size\n",
        "        print(images.size)\n",
        "\n",
        "        predictions = pd.concat([predictions, pred_row], axis=0)\n",
        "\n",
        "    if print_image:\n",
        "      break\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bykWHXK-D4se"
      },
      "outputs": [],
      "source": [
        "#This data is mostly going to be helpful getting summary stats for the entire dataset. \n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_8cSq4UnDGn"
      },
      "outputs": [],
      "source": [
        "predictions.to_excel(\"posts_with_query_matches.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqIVks1Yr326"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhpSoPfdO6ldCxpN0Xh6e6",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}